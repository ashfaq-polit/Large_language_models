{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashfaq-polit/large_language_models/blob/master/GPT_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a GPT\n",
        "\n",
        "Companion notebook to the [Zero To Hero](https://karpathy.ai/zero-to-hero.html) video on GPT."
      ],
      "metadata": {
        "id": "wJpXpmjEYC_T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5hjCcLDr2WC",
        "outputId": "c1036bcc-8f4d-44a2-a9ea-30256b44cfdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-03 01:13:26--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  4.36MB/s    in 0.2s    \n",
            "\n",
            "2025-07-03 01:13:26 (4.36 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read it in to inspect it\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "O6medjfRsLD9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xWI_VyAsN8F",
        "outputId": "dfef3fa4-1051-4c16-b42c-3043a69c2baf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look at the first 1000 characters\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c5V0FvqseE0",
        "outputId": "b1c98f47-7fc0-4bdb-8916-576747d83c85"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e-Rbyr8sfM8",
        "outputId": "0ce38c22-40d8-49e2-a626-d288b59f3449"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw1LKNCgwjj1",
        "outputId": "20da0a2b-b97a-41e8-ba81-bed9d8d78931"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
        "import torch # we use PyTorch: https://pytorch.org\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJb0OXPwzvqg",
        "outputId": "64651e7b-cb9e-4c81-841f-c61c5712a8fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "f_WIXqxz0lU5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD5Bj8Y6IAD4",
        "outputId": "64670cc9-7e82-4141-9f10-439489d23864"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HXDe8vGJCEn",
        "outputId": "5b4c771d-be4a-46be-8493-1a14b85dff5c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([18]) the target: 47\n",
            "when input is tensor([18, 47]) the target: 56\n",
            "when input is tensor([18, 47, 56]) the target: 57\n",
            "when input is tensor([18, 47, 56, 57]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3k1Czf7LuA9",
        "outputId": "872b8ad1-07af-40ff-86a0-7dfae1445322"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
            "----\n",
            "when input is [24] the target: 43\n",
            "when input is [24, 43] the target: 58\n",
            "when input is [24, 43, 58] the target: 5\n",
            "when input is [24, 43, 58, 5] the target: 57\n",
            "when input is [24, 43, 58, 5, 57] the target: 1\n",
            "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
            "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
            "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
            "when input is [44] the target: 53\n",
            "when input is [44, 53] the target: 56\n",
            "when input is [44, 53, 56] the target: 1\n",
            "when input is [44, 53, 56, 1] the target: 58\n",
            "when input is [44, 53, 56, 1, 58] the target: 46\n",
            "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
            "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
            "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52] the target: 58\n",
            "when input is [52, 58] the target: 1\n",
            "when input is [52, 58, 1] the target: 58\n",
            "when input is [52, 58, 1, 58] the target: 46\n",
            "when input is [52, 58, 1, 58, 46] the target: 39\n",
            "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
            "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
            "when input is [25] the target: 17\n",
            "when input is [25, 17] the target: 27\n",
            "when input is [25, 17, 27] the target: 10\n",
            "when input is [25, 17, 27, 10] the target: 0\n",
            "when input is [25, 17, 27, 10, 0] the target: 21\n",
            "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
            "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
            "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb) # our input to the transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpyyAeIzQjlO",
        "outputId": "c09c1874-f6d9-4670-b1e6-ad2efb8c25a6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nql_1ER53oCf",
        "outputId": "7aa589e3-292e-4da2-9a5a-8d10331789dd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "eTyJ8qAaDdiF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(100): # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs4kI8YdEkQj",
        "outputId": "4a04b03b-5b8c-4d7e-df84-2cfda4aabf6b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.587916374206543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcVIDWAZEtjN",
        "outputId": "3a8a208e-3f68-4e10-bc96-d9d00d94bcc6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "xiKi-RJ:CgqVuUa!U?qMH.uk!sCuMXvv!CJFfx;LgRyJknOEti.?I&-gPlLyulId?XlaInQ'q,lT$\n",
            "3Q&sGlvHQ?mqSq-eON\n",
            "x?SP fUAfCAuCX:bOlgiRQWN:Mphaw\n",
            "tRLKuYXEaAXxrcq-gCUzeh3w!AcyaylgYWjmJM?Uzw:inaY,:C&OECW:vmGGJAn3onAuMgia!ms$Vb q-gCOcPcUhOnxJGUGSPJWT:.?ujmJFoiNL&A'DxY,prZ?qdT;hoo'dHooXXlxf'WkHK&u3Q?rqUi.kz;?Yx?C&u3Qbfzxlyh'Vl:zyxjKXgC?\n",
            "lv'QKFiBeviNxO'm!Upm$srm&TqViqiBD3HBP!juEOpmZJyF$Fwfy!PlvWPFC\n",
            "&WDdP!Ko,px\n",
            "x\n",
            "tREOE;AJ.BeXkylOVD3KHp$e?nD,.SFbWWI'ubcL!q-tU;aXmJ&uGXHxJXI&Z!gHRpajj;l.\n",
            "pTErIBjx;JKIgoCnLGXrJSP!AU-AcbczR?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The mathematical trick in self-attention"
      ],
      "metadata": {
        "id": "XinV8nmAnmKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tukiH-NbRBhA",
        "outputId": "d981f6d4-ac08-4ec2-8284-82f5fa1e0815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs_E24uRE8kr",
        "outputId": "fa63e16b-0027-4ed3-f2bb-4fad6c4b39c6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)\n"
      ],
      "metadata": {
        "id": "86NuXX0fn7ps"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "torch.allclose(xbow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhdOAd6-wXkZ",
        "outputId": "655a9d03-0fe0-4c80-fb06-33cc45edf03a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOURrfG-ysoL",
        "outputId": "26e858bc-e113-4006-d2b9-9a5a828b6c83"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 4: self-attention!\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "# let's see a single Head perform self-attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "k = key(x)   # (B, T, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "#wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "#out = wei @ x\n",
        "\n",
        "out.shape\n",
        "\n",
        "# print('key:', k)\n",
        "# print('query:', q)\n",
        "# print('value:', v)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDarxEWIRMKq",
        "outputId": "35c2f36e-5754-4a5b-f513-7742cb717e38"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key: tensor([[[ 1.1965e-01, -3.0127e-01,  3.6293e-01,  1.1771e+00,  1.1385e+00,\n",
            "          -2.5543e-01,  1.4537e-01, -2.9437e-01, -7.0201e-01, -1.0308e+00,\n",
            "           7.4357e-01, -8.0984e-01, -6.6687e-01,  9.1233e-02, -6.0747e-03,\n",
            "           1.9833e-01],\n",
            "         [-5.4229e-01, -5.5581e-01, -7.6131e-02,  1.2929e+00,  8.6535e-01,\n",
            "          -1.1998e+00,  3.8781e-01,  1.9389e-01,  7.0235e-01, -8.2251e-01,\n",
            "           2.3484e-01, -8.4995e-01, -3.8126e-01, -2.9906e-01,  1.0242e-02,\n",
            "          -5.5449e-01],\n",
            "         [-3.7359e-01, -4.6781e-01, -2.1560e-01, -8.0344e-01, -3.7153e-01,\n",
            "          -5.4427e-01, -9.1455e-01, -5.5926e-02, -3.2903e-01, -2.1023e-01,\n",
            "           1.1665e-01, -1.7978e-01, -2.8196e-01, -3.3204e-01, -4.5963e-01,\n",
            "          -1.3255e-01],\n",
            "         [-3.1463e-01,  8.4460e-02, -1.2351e-01, -7.0577e-01, -1.8022e-01,\n",
            "           5.4922e-01, -8.9805e-01, -4.9384e-01,  6.7907e-01,  8.8270e-01,\n",
            "           4.9109e-01,  5.1903e-01,  9.0109e-01,  9.1255e-02, -1.9332e-01,\n",
            "          -6.7704e-01],\n",
            "         [ 2.3940e-02,  9.9822e-02, -1.8709e-01, -8.5960e-02, -4.8815e-01,\n",
            "          -1.6765e+00,  2.4126e-01,  7.3606e-01,  4.6080e-01, -8.7217e-01,\n",
            "          -4.2590e-01, -1.1347e+00, -1.0571e+00, -9.4006e-01,  1.3426e-01,\n",
            "          -1.5716e-02],\n",
            "         [-2.3618e-01, -7.8730e-01, -3.8019e-01,  5.8150e-01, -3.7222e-01,\n",
            "           1.2405e+00, -7.0045e-01, -1.4917e+00,  7.6784e-01,  3.5839e-01,\n",
            "           6.1200e-01, -7.9353e-02,  5.9827e-01,  2.6353e-01,  6.4905e-01,\n",
            "           7.0914e-02],\n",
            "         [-7.9413e-01, -1.6598e-01, -2.8096e-01, -1.0208e-01, -7.3521e-01,\n",
            "          -7.5183e-01, -1.2759e-01, -5.1134e-03,  3.3249e-01, -3.3738e-01,\n",
            "           1.6783e-01,  3.1048e-01,  2.2577e-01,  1.2434e-01,  4.6169e-01,\n",
            "           2.0156e-01],\n",
            "         [ 1.6513e-01, -1.5990e-01, -5.7168e-01, -3.9571e-01,  3.9301e-01,\n",
            "          -8.5665e-01,  3.3900e-01, -7.9771e-01,  2.2134e-01, -5.1612e-01,\n",
            "           1.8504e-01, -2.1048e-01,  3.7789e-01,  4.8222e-02, -4.7437e-01,\n",
            "          -5.0405e-02]],\n",
            "\n",
            "        [[-1.6977e-01, -1.5875e+00, -9.1855e-01,  6.6326e-02, -1.1497e+00,\n",
            "           2.7652e-01, -7.1052e-01, -6.0851e-01, -7.9616e-02, -1.3215e-01,\n",
            "           6.9567e-01,  6.7096e-01,  5.4679e-01,  7.6157e-01,  6.3947e-01,\n",
            "           5.8098e-01],\n",
            "         [-1.1435e-01, -3.5312e-01, -1.8434e-01,  5.2000e-01, -6.0603e-01,\n",
            "           6.3977e-01,  1.2789e-01, -8.0061e-01, -3.9588e-01,  9.8180e-01,\n",
            "          -2.7790e-01, -4.0351e-01, -6.6473e-01,  2.3659e-01,  2.4786e-01,\n",
            "           2.3966e-01],\n",
            "         [-6.3508e-01, -1.0090e+00,  4.4846e-01,  2.6102e-01,  3.0953e-01,\n",
            "           1.0269e+00, -5.0824e-01,  1.5112e-01,  4.9967e-01, -1.0242e+00,\n",
            "           3.3076e-02,  7.9948e-01,  4.7760e-01,  1.0383e-01,  2.8658e-01,\n",
            "           6.3477e-01],\n",
            "         [ 7.1183e-02,  5.7131e-01,  6.2270e-01,  2.4220e-01,  1.1163e+00,\n",
            "           5.2713e-01, -2.7616e-01, -2.8885e-01,  1.6921e-01,  1.0390e+00,\n",
            "          -1.2049e-01, -7.5153e-01,  2.8590e-01, -3.0348e-01, -3.1344e-02,\n",
            "          -6.0875e-01],\n",
            "         [-3.2904e-02,  5.3796e-01,  5.0853e-02,  1.1635e+00, -1.3198e-01,\n",
            "          -8.2809e-01,  3.2218e-01,  2.0548e-01, -1.3409e-01, -2.4342e-01,\n",
            "          -5.2483e-01, -1.0036e+00,  1.4676e-01,  6.1899e-02,  1.1584e-01,\n",
            "          -1.9803e-01],\n",
            "         [-1.5397e-01,  6.4264e-01, -1.2269e-01,  4.0754e-01,  7.2767e-02,\n",
            "          -2.1382e+00,  2.0803e+00,  1.0649e+00,  1.3110e-01, -1.7620e-01,\n",
            "          -1.1203e-02, -1.7259e+00, -7.9774e-01,  1.2679e+00, -6.2352e-03,\n",
            "          -2.9788e-02],\n",
            "         [ 7.5567e-01, -1.1675e-01, -7.9704e-01,  1.6243e-02,  8.6796e-01,\n",
            "          -2.0754e-01,  1.0132e+00, -8.4467e-01,  3.1207e-01,  3.1308e-01,\n",
            "          -4.0251e-01, -5.5028e-01, -1.1918e-02,  1.1328e-01, -1.2361e-01,\n",
            "           2.7873e-01],\n",
            "         [ 1.9565e-01,  1.5312e-01, -2.6387e-01, -9.0676e-01, -8.9970e-01,\n",
            "          -1.5432e-01,  2.9018e-01,  5.1112e-01,  3.9277e-01,  1.4502e-01,\n",
            "          -8.6059e-02,  1.0033e+00,  2.9766e-01, -4.0496e-02, -2.7407e-01,\n",
            "           6.2894e-01]],\n",
            "\n",
            "        [[ 2.1920e-01, -4.3338e-01, -1.7334e-02,  6.1086e-02, -5.0162e-01,\n",
            "          -9.1736e-01, -2.8565e-02, -2.9307e-01,  1.9116e-01,  4.5901e-01,\n",
            "          -6.4669e-01,  2.8410e-01,  7.1452e-01,  5.5001e-01,  7.2716e-02,\n",
            "           1.0264e+00],\n",
            "         [ 1.6208e-01,  4.7036e-01, -1.7571e-01, -1.4430e-01, -4.1618e-01,\n",
            "          -2.7120e-01,  1.7485e-01,  3.4478e-01,  2.0791e-03, -8.3833e-01,\n",
            "           4.8237e-01,  1.4978e-01,  2.6961e-01,  3.1957e-01,  3.1318e-01,\n",
            "           2.4300e-01],\n",
            "         [ 2.3199e-02,  9.1282e-01,  1.2309e-01,  4.3552e-01,  3.1683e-01,\n",
            "           5.4443e-01, -4.1182e-01, -3.9750e-01, -4.6773e-01,  1.4980e-01,\n",
            "          -7.6691e-04,  1.9398e-01, -5.9607e-02,  2.7678e-01,  3.8587e-01,\n",
            "           1.0099e-01],\n",
            "         [ 3.8775e-01, -7.5004e-01,  4.4353e-01,  2.0455e-01,  5.7050e-01,\n",
            "           5.2300e-01, -5.5296e-01,  3.4047e-01, -3.5511e-01, -6.9000e-01,\n",
            "           1.3859e-01, -6.1129e-01,  2.7986e-01, -1.0584e+00, -3.4378e-01,\n",
            "          -6.7254e-01],\n",
            "         [-7.4944e-01,  1.2011e+00,  4.7504e-01, -1.4175e+00, -1.1661e-01,\n",
            "          -2.0519e-01,  4.8880e-02, -5.6190e-01,  1.6865e-01, -5.8476e-01,\n",
            "           1.5643e-01,  2.0620e-01,  3.0129e-01,  3.0515e-01,  1.5822e-01,\n",
            "           1.3580e-01],\n",
            "         [ 3.2854e-03,  8.5792e-02, -3.7273e-01, -4.3263e-01,  2.7126e-01,\n",
            "           5.5295e-01, -3.3752e-01, -3.6228e-01,  3.7946e-01, -5.6956e-01,\n",
            "           3.5850e-01,  5.0297e-01,  8.3247e-01,  2.7065e-01,  2.3051e-01,\n",
            "          -3.7021e-01],\n",
            "         [ 2.6607e-01,  7.4628e-01,  9.7758e-01,  8.5964e-01,  7.2511e-01,\n",
            "          -6.1081e-01, -6.5677e-01, -5.0406e-02, -5.2642e-02,  5.8294e-01,\n",
            "          -4.5590e-02, -3.5460e-02,  9.0733e-01,  2.4781e-01, -1.8979e-01,\n",
            "          -9.3868e-01],\n",
            "         [-9.1529e-01, -9.2379e-01,  2.2234e-01, -3.1099e-01,  3.9580e-01,\n",
            "           5.2756e-01, -4.7417e-01, -2.0447e-01, -2.5679e-01,  3.5713e-01,\n",
            "           1.9908e-01,  7.3336e-02,  6.5161e-01, -2.3829e-01,  5.5460e-01,\n",
            "          -1.9587e-01]],\n",
            "\n",
            "        [[-1.5028e-01, -6.7611e-01, -9.4847e-02,  6.0556e-02, -1.2049e-01,\n",
            "           1.1210e-01,  5.8812e-01,  4.8340e-01, -4.8511e-01,  2.8539e-01,\n",
            "           1.1188e-01, -5.7574e-01,  1.4927e-01,  2.4169e-01, -1.1611e-01,\n",
            "          -1.2201e-01],\n",
            "         [ 3.1164e-01, -9.0459e-02, -2.8066e-01,  2.6897e-01,  6.4195e-01,\n",
            "          -6.5475e-01,  1.1037e+00, -4.5296e-01, -2.1339e-02,  1.6460e-01,\n",
            "           6.7715e-01,  2.3949e-01, -4.3220e-01,  9.4793e-01,  1.7489e-01,\n",
            "          -1.5304e-01],\n",
            "         [-7.9503e-01, -1.4741e+00,  1.1253e+00,  2.7440e-01, -1.4027e+00,\n",
            "           3.7211e-01, -3.9604e-01,  8.4127e-01,  3.5312e-01,  1.4552e-01,\n",
            "           4.2781e-01,  1.1326e+00,  1.9570e-01,  4.9587e-01,  1.9671e-01,\n",
            "           7.6903e-01],\n",
            "         [-3.3249e-01, -5.9558e-01, -2.0805e-01, -5.2000e-01, -1.0317e-01,\n",
            "          -1.0147e+00,  1.2277e-01,  5.6320e-01,  2.6245e-02, -2.8960e-01,\n",
            "           4.3904e-01,  2.1655e-01, -5.1625e-01,  6.9628e-01, -7.1387e-02,\n",
            "           5.5466e-01],\n",
            "         [ 7.1868e-01, -6.9756e-01,  1.7511e-01,  4.2946e-01, -6.4692e-02,\n",
            "           2.1727e-02,  1.6995e-01,  1.0254e-01,  1.7318e-02, -3.4716e-01,\n",
            "          -2.9683e-02,  2.2608e-01, -4.8018e-01, -3.1518e-01,  2.7052e-01,\n",
            "           2.4391e-01],\n",
            "         [-1.8101e-01,  9.1307e-01,  3.3671e-01,  2.0421e-01, -3.9466e-02,\n",
            "           4.7134e-01,  2.1301e-01,  8.5801e-01,  1.5041e-01, -3.7583e-01,\n",
            "          -1.2250e-01, -7.5942e-01,  6.6617e-02, -5.8663e-01, -1.5167e-02,\n",
            "           1.1934e-01],\n",
            "         [-3.1353e-02, -6.3727e-01, -5.9223e-01,  5.9708e-01,  2.5528e-01,\n",
            "          -1.6740e-01,  1.5375e-01, -1.4879e+00,  1.2765e-01,  1.8780e-01,\n",
            "           3.5408e-01, -4.7336e-02, -2.5101e-01,  9.1024e-01, -6.3272e-01,\n",
            "          -2.5878e-01],\n",
            "         [-1.2732e+00, -6.2869e-01,  5.6168e-02, -2.5593e-03, -7.3370e-01,\n",
            "          -2.7521e-01, -1.5650e-01,  3.9314e-01, -4.1830e-01, -1.7399e+00,\n",
            "           6.3731e-01, -6.3222e-01,  4.7992e-01,  1.8370e-01,  1.0338e+00,\n",
            "          -5.4454e-01]]], grad_fn=<UnsafeViewBackward0>)\n",
            "query: tensor([[[-6.5674e-01,  2.8302e-02,  9.4470e-03, -6.9949e-01, -3.6043e-01,\n",
            "           8.3760e-01, -4.4455e-01,  1.2278e-01,  6.2761e-01, -6.2222e-01,\n",
            "           3.4833e-01,  2.4108e-01,  5.4092e-01, -2.6054e-01,  3.6119e-01,\n",
            "          -4.3574e-02],\n",
            "         [-3.9319e-01,  8.2196e-01, -7.0274e-01,  9.5429e-02, -1.2218e-01,\n",
            "          -1.5182e-01, -5.0242e-01, -4.6365e-01,  1.1758e-01,  1.4282e+00,\n",
            "          -5.8116e-01,  1.4008e-01,  9.6041e-01,  4.1002e-02, -6.2136e-01,\n",
            "          -6.3472e-01],\n",
            "         [ 2.1567e-01, -3.5065e-01,  2.1671e-03,  4.2317e-01, -2.2844e-01,\n",
            "          -7.3162e-02, -3.4118e-01,  9.6471e-01, -5.1775e-01,  9.2104e-02,\n",
            "          -5.0425e-01,  8.3885e-01,  6.1487e-01, -1.0894e-02, -5.5692e-01,\n",
            "           5.8197e-01],\n",
            "         [ 8.9999e-01, -1.2723e-01,  5.4581e-01,  4.2544e-01, -4.5128e-01,\n",
            "          -2.1242e-02,  1.7111e-01,  2.5990e-01, -9.9782e-01,  4.8897e-01,\n",
            "           1.7374e-01, -6.9986e-02, -3.1131e-01,  3.7479e-01, -1.8482e-01,\n",
            "          -6.3789e-01],\n",
            "         [ 3.3199e-02,  5.8858e-01, -4.4368e-01,  3.7748e-01, -6.8257e-01,\n",
            "          -2.7749e-01,  4.6726e-01, -1.2956e+00,  6.6032e-01,  1.6333e-01,\n",
            "          -1.7573e+00, -6.5818e-01, -2.3023e-01, -8.6169e-02, -5.9972e-03,\n",
            "           7.5729e-01],\n",
            "         [ 2.0985e-01,  4.3915e-02, -7.0198e-02,  7.2701e-02, -2.0124e-01,\n",
            "          -1.7539e+00,  1.0369e+00,  1.1635e-01,  2.9557e-01,  3.2307e-01,\n",
            "           5.0523e-01,  7.0110e-01, -2.8444e-01, -7.8443e-01,  4.7822e-01,\n",
            "          -5.1704e-01],\n",
            "         [ 6.1001e-01, -3.2841e-01, -8.5571e-01,  8.5427e-01,  7.8055e-01,\n",
            "          -4.0234e-01, -8.1832e-01, -5.5446e-02,  1.8732e-01,  2.7065e-01,\n",
            "          -7.0659e-01, -8.6369e-01,  6.9979e-01, -6.6958e-02,  2.5508e-01,\n",
            "           2.1492e-01],\n",
            "         [ 1.4591e-01,  1.3493e-01, -2.3353e-01, -4.1732e-02,  2.9277e-01,\n",
            "          -5.0801e-01,  1.1770e-01,  1.8610e-01,  1.4554e-01,  2.9240e-02,\n",
            "          -8.4698e-01,  6.1163e-01,  1.2445e+00,  1.9087e-01,  3.6944e-01,\n",
            "          -2.7448e-03]],\n",
            "\n",
            "        [[ 1.1104e+00, -8.7192e-01,  7.0978e-01,  3.6331e-01,  2.0670e-01,\n",
            "          -3.5486e-02, -3.1695e-02,  6.9234e-01, -4.1590e-01, -1.6547e+00,\n",
            "           4.3214e-01, -1.1557e+00,  7.1400e-02, -6.7659e-01,  6.0415e-01,\n",
            "          -5.9200e-01],\n",
            "         [ 3.2561e-01,  5.7866e-01,  5.4575e-01, -7.2274e-01,  1.2343e+00,\n",
            "          -1.5586e-01,  6.8699e-01, -6.3906e-01,  6.1569e-01,  2.1342e-01,\n",
            "          -9.3616e-01,  2.7811e-01,  9.5776e-01,  1.7266e-01, -1.6889e-01,\n",
            "          -1.7047e-02],\n",
            "         [-1.5634e-02, -5.4639e-01,  3.0958e-01,  3.5532e-01,  5.9885e-01,\n",
            "          -8.2791e-01, -5.9326e-01,  7.3282e-01, -4.5197e-01, -8.4692e-01,\n",
            "           5.1515e-01, -1.0304e-02, -2.4767e-01, -6.7420e-02,  1.9623e-03,\n",
            "          -8.3188e-01],\n",
            "         [-2.4959e-01,  2.7492e-01,  2.6894e-01, -3.6563e-01, -3.2585e-01,\n",
            "           3.7158e-01, -8.7898e-01,  1.5132e-01,  3.0180e-02,  3.2213e-01,\n",
            "           3.9398e-01,  6.9950e-01,  9.7176e-02,  8.0347e-02, -1.1911e-02,\n",
            "           3.9823e-01],\n",
            "         [ 3.9181e-01,  5.7756e-01,  1.3630e-01, -3.3129e-01,  3.4955e-01,\n",
            "           3.3893e-01,  2.8573e-01, -3.3917e-01,  6.8701e-01,  3.2722e-01,\n",
            "          -1.0067e+00, -5.3265e-01,  1.0750e+00,  2.7662e-01, -5.8393e-01,\n",
            "          -3.2861e-01],\n",
            "         [ 6.6613e-01,  2.1817e+00, -4.7026e-01,  5.5768e-02, -8.0701e-01,\n",
            "           6.1819e-01,  1.8163e-01, -5.4206e-01,  8.6598e-01,  9.1274e-01,\n",
            "          -1.1465e+00,  1.2842e+00,  2.2156e+00,  8.1063e-01, -1.0830e+00,\n",
            "          -1.6162e-01],\n",
            "         [-5.6865e-01,  4.0198e-01, -5.5940e-01,  2.4041e-01,  2.5784e-02,\n",
            "          -4.5127e-01,  2.0618e-01, -1.1354e-01, -5.3368e-01,  9.9677e-01,\n",
            "          -3.4785e-01,  3.3627e-02,  1.3022e-01, -3.5643e-01,  4.5948e-01,\n",
            "          -3.3823e-01],\n",
            "         [ 5.9567e-01,  2.7697e-01, -5.3694e-01,  3.8806e-01, -5.2068e-01,\n",
            "           6.3736e-02, -4.6341e-01,  1.6976e-01, -6.2182e-01, -8.5360e-01,\n",
            "           1.5969e-02, -4.1913e-01,  7.5529e-01,  3.6444e-01,  4.0385e-01,\n",
            "          -1.9791e-01]],\n",
            "\n",
            "        [[ 1.3326e+00,  1.0350e+00, -1.3503e-02, -9.2348e-01,  1.0694e+00,\n",
            "          -1.4107e-01,  4.7608e-01, -2.5034e-01, -2.9666e-02, -4.9094e-01,\n",
            "          -6.6426e-01,  9.3041e-02,  1.4563e+00,  1.4807e-01, -6.1347e-01,\n",
            "          -1.0926e+00],\n",
            "         [ 5.4338e-01, -1.9188e-01, -5.3040e-01,  6.8131e-01,  6.2352e-02,\n",
            "          -2.8209e-01, -1.6728e-02,  5.4435e-01, -3.0124e-01, -1.1855e-01,\n",
            "          -1.8417e-01, -4.8132e-01, -2.1184e-01,  2.4121e-01,  2.1798e-02,\n",
            "          -6.9178e-02],\n",
            "         [-3.3528e-01, -5.6466e-01,  6.6484e-01, -1.5190e-01,  3.6304e-01,\n",
            "           6.2404e-01, -2.4197e-01,  1.1305e+00,  1.7005e-01,  3.6276e-01,\n",
            "           8.0700e-01, -1.0924e-01,  1.9538e-01, -4.2642e-01, -6.4841e-01,\n",
            "          -2.0725e-01],\n",
            "         [-1.0337e-01,  8.0347e-02, -3.1804e-01, -1.0417e+00,  6.4425e-02,\n",
            "          -4.2446e-01,  4.8210e-01,  2.6664e-01, -5.0266e-01, -1.4787e+00,\n",
            "           1.0776e+00,  2.1790e-01, -8.7924e-01,  1.0318e-01,  1.1044e-01,\n",
            "          -8.6890e-01],\n",
            "         [ 7.3975e-01, -5.6316e-01,  6.8825e-01,  6.8188e-01,  9.2013e-01,\n",
            "          -6.6580e-01, -2.3015e-01,  3.4094e-01,  4.4395e-01,  6.7518e-01,\n",
            "           2.6042e-01,  1.4252e+00,  7.6539e-01,  2.5805e-01, -7.9161e-01,\n",
            "           7.3077e-01],\n",
            "         [ 4.9907e-02, -4.8685e-01,  2.1094e-01, -3.5810e-01,  1.2313e-01,\n",
            "           1.5951e-01,  1.7245e-01,  2.8349e-01, -2.1648e-01, -5.0059e-01,\n",
            "          -2.0210e-01,  2.4838e-01,  1.3610e-02,  1.0566e+00,  2.7065e-01,\n",
            "          -4.7702e-01],\n",
            "         [-6.4012e-01,  4.7867e-02, -2.7659e-02, -5.3705e-01,  4.5048e-01,\n",
            "           2.2384e-01, -1.1379e+00,  5.9782e-01,  1.0890e-02, -4.5584e-01,\n",
            "           7.9715e-01,  3.0061e-01,  7.8801e-01, -2.9773e-01, -1.7181e-01,\n",
            "          -7.1184e-01],\n",
            "         [ 4.1349e-02, -6.6965e-01, -4.0473e-01, -8.1760e-01, -1.4332e-01,\n",
            "          -2.2694e-01,  8.5180e-02,  3.4696e-01,  2.9030e-02,  2.2824e-01,\n",
            "           4.9848e-01,  3.6049e-01, -4.2176e-01, -5.3471e-01, -5.0211e-02,\n",
            "           1.8603e-01]],\n",
            "\n",
            "        [[ 6.2212e-04,  3.1138e-01, -7.1241e-01, -5.4445e-01,  8.2328e-01,\n",
            "          -1.6868e-01,  2.2658e-01,  4.8862e-01, -7.2207e-01,  3.6705e-01,\n",
            "          -1.3507e-01,  3.5477e-02, -4.4308e-01, -4.5602e-01, -9.0744e-01,\n",
            "          -2.2787e-01],\n",
            "         [-8.5366e-01, -1.1014e-02, -1.6077e-01,  1.7789e-03, -1.3390e-01,\n",
            "          -4.7289e-01, -2.1686e-01,  4.3677e-01,  8.0428e-01,  1.0344e+00,\n",
            "           8.8352e-03,  2.7911e-01, -7.6171e-02, -7.9940e-01,  4.4846e-01,\n",
            "           7.0971e-01],\n",
            "         [ 1.4088e+00, -4.4377e-02, -2.5436e-03,  1.2366e-01,  5.7979e-01,\n",
            "          -7.1957e-01, -5.0969e-01, -8.0928e-01, -8.9076e-02, -7.4968e-02,\n",
            "          -8.5395e-01, -1.5098e+00, -1.1381e+00, -6.0501e-02,  1.5464e-01,\n",
            "           3.2477e-01],\n",
            "         [ 1.9741e-01, -2.5031e-01, -1.2182e-01,  4.9976e-01,  2.4592e-01,\n",
            "           6.9912e-01, -4.1537e-01, -1.3993e+00,  5.9324e-01,  7.7563e-02,\n",
            "          -1.0144e+00, -8.3186e-01,  1.7011e-01, -3.2685e-01,  6.3889e-01,\n",
            "          -9.1289e-03],\n",
            "         [-1.1387e-02,  8.6315e-01,  2.5427e-01, -3.2685e-02, -1.1675e-02,\n",
            "          -6.4872e-01,  1.3967e-01, -1.2100e-01, -3.6965e-01, -3.9830e-01,\n",
            "           2.0917e-01, -4.2211e-02,  3.5471e-01, -1.4781e-02,  1.0395e-01,\n",
            "          -8.2862e-01],\n",
            "         [-3.7612e-01, -7.3518e-02, -1.1904e+00,  7.2211e-01,  2.6136e-01,\n",
            "          -3.6523e-01,  1.0752e+00, -4.8674e-01, -4.3567e-01,  1.3338e-01,\n",
            "           6.0010e-01, -3.8806e-01, -1.5267e+00, -3.4049e-01,  3.2029e-01,\n",
            "          -3.5348e-01],\n",
            "         [-3.8176e-01,  7.8970e-01,  8.1802e-01,  8.8146e-01,  7.0618e-01,\n",
            "          -6.2861e-01, -6.7371e-01, -1.7663e-01,  5.2108e-01,  6.6437e-01,\n",
            "          -8.8697e-01,  5.0958e-02,  6.5746e-01, -6.3669e-01, -8.9697e-02,\n",
            "           3.2022e-01],\n",
            "         [-3.0550e-01,  8.9354e-02, -2.3808e-01,  1.0563e+00,  3.4164e-01,\n",
            "          -9.2939e-01,  8.5246e-01,  2.3477e-02,  1.6643e-01, -1.2088e+00,\n",
            "          -2.5446e-01,  6.6724e-01, -1.5612e-01, -1.7337e-01,  1.2187e-01,\n",
            "           2.0050e-01]]], grad_fn=<UnsafeViewBackward0>)\n",
            "value: tensor([[[-1.5713e-01,  8.8009e-01,  1.6152e-01, -7.8239e-01, -1.4289e-01,\n",
            "           7.4676e-01,  1.0068e-01, -5.2395e-01, -8.8726e-01,  1.9068e-01,\n",
            "           1.7616e-01, -5.9426e-01, -4.8124e-01, -4.8599e-01,  2.8623e-01,\n",
            "           5.7099e-01],\n",
            "         [ 8.3212e-01, -8.1437e-01, -3.2425e-01,  5.1913e-01, -1.2520e-01,\n",
            "          -4.8982e-01, -5.2867e-01, -3.1393e-02,  1.0723e-01,  8.2692e-01,\n",
            "           8.1322e-01, -2.7132e-02,  4.7754e-01,  4.9801e-01, -1.3769e-01,\n",
            "           1.4025e+00],\n",
            "         [ 6.0346e-01, -2.4995e-01, -6.1588e-01,  4.0678e-01,  3.3283e-01,\n",
            "          -3.9097e-01,  1.3119e-01,  2.1718e-01, -1.2991e-01, -8.8281e-01,\n",
            "           1.7242e-01,  4.6522e-01, -4.2710e-01, -7.6754e-02, -2.8524e-01,\n",
            "           1.3875e+00],\n",
            "         [ 6.6568e-01, -7.0960e-01, -6.0986e-01,  4.3484e-01,  8.9754e-01,\n",
            "          -9.2983e-01,  6.8325e-02,  1.8632e-01,  5.4002e-01,  2.4271e-01,\n",
            "          -6.9225e-01,  4.9774e-01,  4.8503e-01,  6.6076e-01,  8.7671e-01,\n",
            "           7.4566e-02],\n",
            "         [ 1.5357e-01,  1.0439e+00,  8.4574e-01,  2.3882e-01,  3.0046e-01,\n",
            "           1.0516e+00,  7.6373e-01,  4.5166e-01, -7.4263e-01, -1.4395e+00,\n",
            "          -4.9412e-01, -3.7087e-01, -1.1819e+00,  1.0001e-01, -1.8065e-01,\n",
            "           5.1291e-01],\n",
            "         [-8.9198e-01,  5.7820e-02, -3.3504e-01,  8.4768e-01,  3.8764e-01,\n",
            "           1.6644e-01, -4.5871e-01, -5.9737e-01,  4.9612e-01,  6.5476e-01,\n",
            "           5.4789e-02,  9.4680e-01,  4.5108e-01,  1.1999e-01,  1.0573e+00,\n",
            "          -2.2570e-01],\n",
            "         [-4.8492e-01,  1.6553e-01, -2.2215e-01, -1.3454e-01, -8.6441e-02,\n",
            "          -6.6281e-01, -9.3596e-02,  1.0496e-01, -2.6121e-01,  1.8538e-01,\n",
            "           3.1711e-01, -1.3927e-01,  5.4862e-01, -4.0864e-01, -3.8507e-01,\n",
            "           7.1057e-01],\n",
            "         [ 2.0424e-01,  3.7717e-01, -1.1255e+00,  3.9950e-01,  1.4892e-01,\n",
            "           3.5902e-01, -1.7912e-01,  1.3732e+00,  1.5880e-01, -2.3202e-01,\n",
            "           1.6507e-01,  7.6043e-01,  3.5211e-01, -1.0864e+00, -7.9393e-01,\n",
            "          -3.0253e-01]],\n",
            "\n",
            "        [[-1.3254e+00,  1.1236e+00,  2.2927e-01, -2.9970e-01, -7.6267e-03,\n",
            "           7.9364e-01,  8.9581e-01,  3.9650e-01, -6.6613e-01, -2.1844e-01,\n",
            "          -1.3539e+00,  4.1245e-01,  9.6011e-01, -1.0805e+00, -3.9751e-01,\n",
            "          -4.4439e-01],\n",
            "         [-1.9221e-01, -4.6449e-01,  5.9880e-02,  2.8408e-01, -1.0312e-01,\n",
            "          -1.7967e-03,  1.8920e-01, -3.7337e-01, -9.8137e-02,  2.3116e-02,\n",
            "           8.5743e-01,  5.6841e-01, -2.1939e-01, -2.9158e-01, -2.0158e-01,\n",
            "          -4.6876e-01],\n",
            "         [-1.1012e+00,  9.8266e-02,  5.8596e-01, -5.6413e-03,  3.7330e-01,\n",
            "          -6.1363e-02,  2.8833e-02,  2.6230e-01,  6.4099e-01,  7.1003e-02,\n",
            "           3.6877e-01,  5.0011e-01,  7.3872e-01,  1.1909e-01,  5.4246e-01,\n",
            "           6.8950e-02],\n",
            "         [ 4.9074e-01, -2.9978e-01,  1.0949e+00,  1.0131e+00,  3.5883e-01,\n",
            "           9.5771e-01, -1.8349e-01,  1.4002e-01,  1.4243e-01,  8.0787e-01,\n",
            "          -2.4476e-01,  1.3392e-01,  2.6700e-01,  3.2605e-01,  2.0296e-01,\n",
            "           1.4967e-01],\n",
            "         [ 4.5700e-02,  1.0993e+00,  4.6545e-01, -1.5803e-01, -7.2921e-01,\n",
            "           5.8145e-01,  4.0171e-01,  1.3040e+00, -2.2263e-02,  3.9847e-01,\n",
            "           6.3218e-01, -1.4205e-01,  5.0596e-01, -2.9585e-01, -3.5306e-02,\n",
            "          -7.2087e-01],\n",
            "         [ 3.6249e-01,  3.1444e-01,  3.7844e-01, -3.3100e-01, -1.1213e+00,\n",
            "          -6.8686e-01, -6.5431e-01, -2.1805e-01, -2.6552e-01,  6.7712e-01,\n",
            "           3.9176e-01, -1.3338e+00,  3.7350e-01, -1.1095e+00,  3.7270e-01,\n",
            "          -9.3442e-01],\n",
            "         [-2.0881e-01, -7.6620e-02, -1.5674e-01,  1.4457e-01,  8.7035e-01,\n",
            "           2.1136e-01, -4.8995e-01,  2.4986e-01,  5.1811e-01,  6.6507e-01,\n",
            "           3.2814e-01,  4.6015e-01,  9.2321e-01, -4.5579e-01, -4.8577e-01,\n",
            "          -2.7199e-01],\n",
            "         [-1.8408e-01,  1.7347e-01,  1.4034e-02, -4.8221e-01, -5.2118e-01,\n",
            "          -2.6668e-01, -1.0874e-01,  2.0809e-01,  3.0165e-01,  5.3594e-02,\n",
            "          -3.7746e-01, -7.4163e-01,  8.8692e-04, -1.2250e+00,  3.0022e-01,\n",
            "          -5.0357e-01]],\n",
            "\n",
            "        [[ 6.8925e-02,  1.2248e+00, -4.1194e-01, -1.7046e-01, -6.9224e-01,\n",
            "          -2.9201e-01,  1.2704e+00, -6.8596e-01,  4.3798e-01, -2.6366e-01,\n",
            "           1.1528e-01,  1.1676e+00, -7.2138e-01, -1.2308e+00,  8.3821e-01,\n",
            "          -5.5987e-01],\n",
            "         [-9.5939e-01,  9.2166e-02,  7.7470e-02, -9.8325e-02, -5.0263e-01,\n",
            "          -7.0076e-01, -7.3248e-01,  1.8081e-02,  4.7626e-01, -1.1356e-01,\n",
            "           2.6368e-01, -3.6124e-01, -2.1905e-02, -3.4626e-01, -1.0357e-01,\n",
            "           6.5548e-01],\n",
            "         [-5.7584e-01, -3.0022e-01, -6.9503e-02, -9.9645e-02, -2.8187e-01,\n",
            "          -6.7841e-01, -1.4310e-01, -3.7591e-01,  5.7496e-01,  4.6758e-04,\n",
            "           9.1726e-01,  1.6101e-01, -4.4098e-01,  5.3701e-03,  7.9788e-01,\n",
            "           5.6693e-01],\n",
            "         [ 3.4514e-01,  3.0841e-01,  1.0998e-01, -2.6316e-01,  1.0666e+00,\n",
            "          -5.6067e-02, -6.9560e-01,  3.0091e-01, -2.7254e-01,  8.2122e-01,\n",
            "          -8.6185e-01,  6.1082e-02, -1.2083e-01,  4.1112e-01, -1.0277e-01,\n",
            "          -2.9790e-01],\n",
            "         [-1.8289e+00, -8.6379e-01, -7.9821e-01,  2.4173e-01, -5.0344e-01,\n",
            "          -1.0447e+00,  8.7287e-01,  5.0584e-01,  5.6657e-02, -3.1938e-01,\n",
            "           1.0980e+00,  1.1729e+00, -5.4148e-01, -1.0805e+00,  7.3217e-02,\n",
            "          -2.8329e-01],\n",
            "         [-3.5718e-01, -3.2740e-01, -6.9867e-01,  7.8014e-01,  4.2778e-01,\n",
            "           3.3665e-01,  5.5142e-02,  5.9465e-01,  6.4841e-01, -8.7773e-02,\n",
            "          -4.3907e-02,  6.5681e-01,  1.2646e-01,  2.5969e-01,  6.7423e-01,\n",
            "          -7.6637e-01],\n",
            "         [ 7.6206e-01,  4.9035e-01,  8.2749e-01,  3.7294e-01, -7.1975e-01,\n",
            "          -3.3127e-01, -8.6443e-01, -1.6571e-03, -5.9054e-01,  6.3868e-01,\n",
            "           2.2889e-01, -5.5488e-02,  2.9504e-01,  5.3679e-01, -7.7014e-01,\n",
            "           4.9259e-01],\n",
            "         [ 4.3940e-01,  2.4456e-01, -6.1958e-01,  5.1417e-01,  8.1137e-01,\n",
            "           2.7439e-01,  1.6661e-01,  5.0555e-02,  9.1574e-02,  8.9894e-01,\n",
            "          -1.0681e-01,  3.1970e-01, -7.3390e-02,  3.0807e-01,  7.9702e-01,\n",
            "           7.5018e-01]],\n",
            "\n",
            "        [[ 9.7183e-02,  5.7301e-02, -1.0468e-01, -4.6654e-02, -1.4006e-01,\n",
            "          -8.4126e-01, -1.3625e-01, -6.7465e-01, -2.1541e-01,  1.0993e+00,\n",
            "           2.3427e-01,  3.2605e-02, -1.8521e-01,  1.4780e-01, -6.1045e-01,\n",
            "           1.5391e+00],\n",
            "         [ 3.6123e-01, -6.7973e-01, -7.7090e-01,  6.4828e-01, -2.4451e-01,\n",
            "          -5.7902e-01, -1.5354e+00, -7.2195e-01, -1.8834e-01,  1.0884e-02,\n",
            "           2.3991e-01, -5.4473e-02, -1.4373e-01,  4.9291e-02, -8.8639e-01,\n",
            "           7.2397e-01],\n",
            "         [-1.0977e-01,  8.0600e-01,  8.1140e-01, -3.4001e-01, -4.5837e-01,\n",
            "           5.4328e-03,  1.3075e+00, -7.7781e-01, -6.2820e-01,  7.4216e-02,\n",
            "          -2.1868e-01,  1.8126e-01, -2.0854e-01,  6.7201e-01,  6.9363e-02,\n",
            "           9.8662e-01],\n",
            "         [ 3.0428e-01,  1.1563e+00,  1.3803e-01, -2.0818e+00, -1.0470e-01,\n",
            "           5.2292e-01,  1.2301e+00,  5.3652e-01, -9.0009e-01, -1.0794e+00,\n",
            "          -2.4331e-01,  9.7983e-04,  2.4827e-01,  4.4169e-02, -6.7854e-01,\n",
            "          -3.3345e-01],\n",
            "         [-5.3004e-01, -9.2135e-01,  3.7915e-01, -2.0732e-02,  3.7330e-01,\n",
            "          -1.6131e-01, -7.0930e-01,  4.2039e-02,  1.6151e-01,  1.6618e-01,\n",
            "           5.6694e-01,  5.5056e-01, -7.1126e-02, -5.5536e-01, -1.2077e-01,\n",
            "          -4.5284e-01],\n",
            "         [-6.9652e-01,  4.4457e-01,  8.0947e-01, -6.0359e-01,  4.7886e-02,\n",
            "          -4.6401e-01, -2.0967e-01,  5.5984e-01,  5.7196e-01,  3.6429e-01,\n",
            "           5.9383e-02, -1.3565e+00,  6.8667e-01,  5.4511e-01, -6.7370e-01,\n",
            "           6.3525e-01],\n",
            "         [ 3.5459e-01,  1.1575e-01, -4.2291e-01, -4.7040e-01, -2.2670e-01,\n",
            "           1.5671e-01, -2.1000e-01, -1.0505e+00, -1.0665e+00, -8.3185e-01,\n",
            "           1.9891e-01,  9.0778e-01,  3.5189e-01,  5.6643e-02, -6.4876e-01,\n",
            "           5.5124e-02],\n",
            "         [-1.7223e+00,  5.1077e-01,  2.9681e-01,  2.3290e-01,  2.4183e-01,\n",
            "           3.3723e-01, -2.5232e-01,  6.4762e-01, -1.4068e+00, -6.4379e-01,\n",
            "           7.4489e-02, -5.8730e-01,  1.2959e-01, -2.1585e-01, -7.5063e-01,\n",
            "           3.2311e-01]]], grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT1hdtzXCjgL",
        "outputId": "6af2d853-648f-4fca-c2c0-d00226d999e3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
              "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
              "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# 1. Set seed and create input\n",
        "torch.manual_seed(1337)\n",
        "B, T, C = 4, 8, 32\n",
        "x = torch.randn(B, T, C)\n",
        "\n",
        "# 2. Linear projections\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "\n",
        "k = key(x)       # (B, T, 16)\n",
        "q = query(x)     # (B, T, 16)\n",
        "\n",
        "# 3. Compute raw attention scores\n",
        "wei = q @ k.transpose(-2, -1)  # (B, T, T)\n",
        "\n",
        "# 4. Apply causal mask\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "\n",
        "# 5. Convert to probabilities\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "# 6. Project to value and get output\n",
        "v = value(x)\n",
        "out = wei @ v  # (B, T, 16)\n",
        "\n",
        "# 7. --- Visualize attention map ---\n",
        "sample_idx = 0  # pick one example from batch\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(wei[sample_idx].detach().numpy(), cmap='viridis', cbar=True, square=True,\n",
        "            xticklabels=[f't{i}' for i in range(T)],\n",
        "            yticklabels=[f't{i}' for i in range(T)])\n",
        "plt.xlabel('Attending to')\n",
        "plt.ylabel('Token at position')\n",
        "plt.title('Self-Attention Weights (Sample 0)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "V3h21o_Gbe5f",
        "outputId": "42d4ad04-0f4b-4ca0-c63e-5be6baf1c1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
        "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
        "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
        "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
        "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
        "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
      ],
      "metadata": {
        "id": "M5CvobiQ0pLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = torch.randn(B,T,head_size)\n",
        "q = torch.randn(B,T,head_size)\n",
        "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
      ],
      "metadata": {
        "id": "4SNbLq5z3oBw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl6I9n9IRTSo",
        "outputId": "362d172a-b0f1-4de6-f65e-a14253a6358b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0449)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1tQx7oeRvtc",
        "outputId": "aa2805c0-1dd6-48ea-8229-f9c09e25d411"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0700)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLb_odHU3iKM",
        "outputId": "a824c495-7da6-438d-f49c-39d1ab570aa9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0918)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB82yzt44REI",
        "outputId": "07583290-6794-4083-c7ac-335717d90121"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpt8569BB9_f",
        "outputId": "8ded9d3f-883b-4be8-ee47-db6045a94b23"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm1d: # (used to be BatchNorm1d)\n",
        "\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # calculate the forward pass\n",
        "    xmean = x.mean(1, keepdim=True) # batch mean\n",
        "    xvar = x.var(1, keepdim=True) # batch variance\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "module = LayerNorm1d(100)\n",
        "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
        "x = module(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Num7sX9CKOH",
        "outputId": "811e46f7-330f-4ccb-aeea-792ca249e9da"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "633T2cmnW1uk",
        "outputId": "91192b0c-1616-4540-e986-4a9104d8953b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1469), tensor(0.8803))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN9cK9BoXCYb",
        "outputId": "1e3920eb-7481-47da-f843-d78a27b45a9e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-9.5367e-09), tensor(1.0000))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# French to English translation example:\n",
        "\n",
        "# <--------- ENCODE ------------------><--------------- DECODE ----------------->\n",
        "# les réseaux de neurones sont géniaux! <START> neural networks are awesome!<END>\n",
        "\n"
      ],
      "metadata": {
        "id": "dRJH6wM_XFfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full finished code, for reference\n",
        "\n",
        "You may want to refer directly to the git repo instead though."
      ],
      "metadata": {
        "id": "ZcvKeBXoZFOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "# super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoelkOrFY8bN",
        "outputId": "6ab46caf-82bf-4ddf-9303-36387c699476"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.209729 M parameters\n",
            "step 0: train loss 4.4116, val loss 4.4022\n",
            "step 100: train loss 2.6568, val loss 2.6670\n",
            "step 200: train loss 2.5090, val loss 2.5058\n",
            "step 300: train loss 2.4194, val loss 2.4335\n",
            "step 400: train loss 2.3503, val loss 2.3567\n",
            "step 500: train loss 2.2964, val loss 2.3131\n",
            "step 600: train loss 2.2404, val loss 2.2494\n",
            "step 700: train loss 2.2043, val loss 2.2177\n",
            "step 800: train loss 2.1629, val loss 2.1856\n",
            "step 900: train loss 2.1240, val loss 2.1500\n",
            "step 1000: train loss 2.1015, val loss 2.1286\n",
            "step 1100: train loss 2.0685, val loss 2.1178\n",
            "step 1200: train loss 2.0382, val loss 2.0792\n",
            "step 1300: train loss 2.0251, val loss 2.0637\n",
            "step 1400: train loss 1.9940, val loss 2.0377\n",
            "step 1500: train loss 1.9691, val loss 2.0310\n",
            "step 1600: train loss 1.9631, val loss 2.0481\n",
            "step 1700: train loss 1.9402, val loss 2.0124\n",
            "step 1800: train loss 1.9091, val loss 1.9958\n",
            "step 1900: train loss 1.9069, val loss 1.9857\n",
            "step 2000: train loss 1.8835, val loss 1.9925\n",
            "step 2100: train loss 1.8699, val loss 1.9730\n",
            "step 2200: train loss 1.8584, val loss 1.9597\n",
            "step 2300: train loss 1.8541, val loss 1.9527\n",
            "step 2400: train loss 1.8412, val loss 1.9423\n",
            "step 2500: train loss 1.8159, val loss 1.9411\n",
            "step 2600: train loss 1.8222, val loss 1.9347\n",
            "step 2700: train loss 1.8097, val loss 1.9322\n",
            "step 2800: train loss 1.8011, val loss 1.9174\n",
            "step 2900: train loss 1.8024, val loss 1.9276\n",
            "step 3000: train loss 1.7929, val loss 1.9140\n",
            "step 3100: train loss 1.7686, val loss 1.9183\n",
            "step 3200: train loss 1.7549, val loss 1.9115\n",
            "step 3300: train loss 1.7564, val loss 1.9077\n",
            "step 3400: train loss 1.7538, val loss 1.8954\n",
            "step 3500: train loss 1.7379, val loss 1.8958\n",
            "step 3600: train loss 1.7259, val loss 1.8883\n",
            "step 3700: train loss 1.7280, val loss 1.8791\n",
            "step 3800: train loss 1.7193, val loss 1.8886\n",
            "step 3900: train loss 1.7200, val loss 1.8695\n",
            "step 4000: train loss 1.7137, val loss 1.8615\n",
            "step 4100: train loss 1.7141, val loss 1.8754\n",
            "step 4200: train loss 1.7045, val loss 1.8624\n",
            "step 4300: train loss 1.7004, val loss 1.8476\n",
            "step 4400: train loss 1.7074, val loss 1.8726\n",
            "step 4500: train loss 1.6920, val loss 1.8539\n",
            "step 4600: train loss 1.6896, val loss 1.8382\n",
            "step 4700: train loss 1.6828, val loss 1.8444\n",
            "step 4800: train loss 1.6671, val loss 1.8474\n",
            "step 4900: train loss 1.6731, val loss 1.8416\n",
            "step 4999: train loss 1.6671, val loss 1.8286\n",
            "\n",
            "ROMEO:\n",
            "But you fret, hell, whereIV: it they to duke I usprocely fittle offect I'll wanter.\n",
            "\n",
            "BONDINGHNOR:\n",
            "You! but usom upwor your myst gliman;\n",
            "This Iell thre sure hanch them nour gruars:\n",
            "Now to by betwereight, tow, go:\n",
            "Eve not, Doh souls shall; them Those not.\n",
            "\n",
            "LUCIO:\n",
            "Lord,----\n",
            "But thou sging them this my freceim\n",
            "sear\n",
            "By Look's to; contray\n",
            "futwair art sade but grove to him, he's subdore in that lest.\n",
            "\n",
            "GLOUCESTER:\n",
            "Faway, as I neat.\n",
            "\n",
            "MENRIZERENB:\n",
            "Olving this swame, but strave so grain.\n",
            "\n",
            "MENENIUS:\n",
            "Geniry's bigguardsly come;\n",
            "Haid trues forsweet, sirr.\n",
            "\n",
            "POMPEREY:\n",
            "These stonge toe as passon\n",
            "The from throw and potater?\n",
            "\n",
            "Secome:\n",
            "Henrath my in fortunue: my latchmant I late all that you by joyly us belt slinem.\n",
            "\n",
            "KING-\n",
            "FRUKHESS My shalt juntance: that you, prinring Afflorceling\n",
            "What colforth temine you wast shoult where forpend,\n",
            "And-finus I'll that confect I come,\n",
            "But; man.\n",
            "\n",
            "BRUCKINGHASS:\n",
            "On you, argive, with surnes diphnsbreath\n",
            "Herefare, name a dought, thou\n",
            "Then fathers mades exety with.\n",
            "\n",
            "GLOUCESTER:\n",
            "Fixe.\n",
            "Is I would madie, no an it that would patch evile turn than war.\n",
            "\n",
            "LUCENTIO:\n",
            "I usquelch here crovides.\n",
            "\n",
            "PUARIEE:\n",
            "It that advoutly since, and marry.\n",
            "Mut wondy worse is senst my long.\n",
            "\n",
            "YORYVUPURENCELIO:\n",
            "Yest humast of the loves my lord:\n",
            "New, his stort not his morst.\n",
            "You more, to\n",
            "nom a rathing if thyseal,\n",
            "On think, if by yold, thou how onferds frulling.\n",
            "\n",
            "RICHARD:\n",
            "The steam, it you:\n",
            "Onfull him it no ars. I so gettles,\n",
            "I ande such the cruntion the rest:\n",
            "My brive, he get belaw, with the his say\n",
            "as towns, pressions: you lom if curner,\n",
            "But unter, toges, by aft, fantes, Bety on the,\n",
            "Pronge unteett, thou make-banited?\n",
            "\n",
            "LORD GAURET:\n",
            "These what reagt say mover a desbriek which o' an the;\n",
            "O, you to\n",
            "mellike they us thus usspried with requmate,\n",
            "All leats, bretcius unfeece that I would back with wowith you wind you,\n",
            "My leave it. Delporte these, be to stless this high pray poolaful brittles sure make Destiture,\n",
            "At not yet have contress. Thou prant!\n",
            "O,' you goligh you. Come flippown,\n",
            "And fatt\n"
          ]
        }
      ]
    }
  ]
}