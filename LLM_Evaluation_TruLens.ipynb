{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOT4zbuX1vk5YYOsEX953v6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3225be5b40da496eb3767405ede6bec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_606088ed949043209545162672568f4e",
              "IPY_MODEL_7e26852f8a2e4c4ea2256e84fa5c2f09",
              "IPY_MODEL_05f46dec29b44438b657c68b7564291f"
            ],
            "layout": "IPY_MODEL_86b6e8b7fcd647b4a4c3182d78a8cd61"
          }
        },
        "606088ed949043209545162672568f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15e7091ba0ad4bdda900e0d1742ac3d8",
            "placeholder": "​",
            "style": "IPY_MODEL_5fb3c8cbec964b81ad76868fc5a18c14",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7e26852f8a2e4c4ea2256e84fa5c2f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03f3cc4840294c1480f64f767a9831ba",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd6c453e1faf40d98be45e552e1ec198",
            "value": 4
          }
        },
        "05f46dec29b44438b657c68b7564291f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d61e2f3e74da47e4bee29eb65676612f",
            "placeholder": "​",
            "style": "IPY_MODEL_a2996e26ee0144faaa2b6ff3206dd4a7",
            "value": " 4/4 [00:04&lt;00:00,  1.00s/it]"
          }
        },
        "86b6e8b7fcd647b4a4c3182d78a8cd61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15e7091ba0ad4bdda900e0d1742ac3d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fb3c8cbec964b81ad76868fc5a18c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03f3cc4840294c1480f64f767a9831ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd6c453e1faf40d98be45e552e1ec198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d61e2f3e74da47e4bee29eb65676612f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2996e26ee0144faaa2b6ff3206dd4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashfaq-polit/Large_language_models/blob/master/LLM_Evaluation_TruLens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY_IGyyRhL29",
        "outputId": "6c9ee1c5-3c68-487e-b941-d0a155e759e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m129.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.6/284.6 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.5/305.5 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-index llama-index-llms-huggingface llama-index-embeddings-huggingface transformers accelerate bitsandbytes langchain_community\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install llama-index-llms-langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nMqPI5tvmxYM",
        "outputId": "17270911-399e-4819-8d5e-b53a5c5d6d28"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-llms-langchain\n",
            "  Downloading llama_index_llms_langchain-0.6.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: langchain>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-langchain) (0.3.26)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-langchain) (0.12.48)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain>=0.1.7->llama-index-llms-langchain) (0.3.68)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain>=0.1.7->llama-index-llms-langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain>=0.1.7->llama-index-llms-langchain) (0.4.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain>=0.1.7->llama-index-llms-langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain>=0.1.7->llama-index-llms-langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain>=0.1.7->llama-index-llms-langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain>=0.1.7->llama-index-llms-langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (2.1.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (1.1.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (11.2.1)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (80.9.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (4.3.8)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain>=0.1.7->llama-index-llms-langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain>=0.1.7->llama-index-llms-langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain>=0.1.7->llama-index-llms-langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain>=0.1.7->llama-index-llms-langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain>=0.1.7->llama-index-llms-langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (0.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.7->llama-index-llms-langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.7->llama-index-llms-langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.7->llama-index-llms-langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain>=0.1.7->llama-index-llms-langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain>=0.1.7->llama-index-llms-langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain>=0.1.7->llama-index-llms-langchain) (3.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (3.26.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain>=0.1.7->llama-index-llms-langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-langchain) (3.0.2)\n",
            "Downloading llama_index_llms_langchain-0.6.1-py3-none-any.whl (6.1 kB)\n",
            "Installing collected packages: llama-index-llms-langchain\n",
            "Successfully installed llama-index-llms-langchain-0.6.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "llama_index"
                ]
              },
              "id": "1c7ffdc7b7b5498c98afa6ca71884f37"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3bb897b0",
        "outputId": "763f48aa-dcba-4e86-daab-86ac246dcd26"
      },
      "source": [
        "# !pip install -q trulens_eval\n",
        "!pip install \"trulens-apps-llamaindex>=1.0.0\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trulens-apps-llamaindex>=1.0.0\n",
            "  Downloading trulens_apps_llamaindex-1.5.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: llama-index>=0.11 in /usr/local/lib/python3.11/dist-packages (from trulens-apps-llamaindex>=1.0.0) (0.12.48)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from trulens-apps-llamaindex>=1.0.0) (2.11.7)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from trulens-apps-llamaindex>=1.0.0) (0.9.0)\n",
            "Collecting trulens-apps-langchain<2.0.0,>=1.0.0 (from trulens-apps-llamaindex>=1.0.0)\n",
            "  Downloading trulens_apps_langchain-1.5.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: trulens-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from trulens-apps-llamaindex>=1.0.0) (1.5.3)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.4.12)\n",
            "Requirement already satisfied: llama-index-cli<0.5,>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.4.4)\n",
            "Requirement already satisfied: llama-index-core<0.13,>=0.12.48 in /usr/local/lib/python3.11/dist-packages (from llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.12.48)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.7.10)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.4.7)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.5.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.3.2)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.3.1)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.4.11)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (3.9.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->trulens-apps-llamaindex>=1.0.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->trulens-apps-llamaindex>=1.0.0) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->trulens-apps-llamaindex>=1.0.0) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->trulens-apps-llamaindex>=1.0.0) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.3.3->trulens-apps-llamaindex>=1.0.0) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.3.3->trulens-apps-llamaindex>=1.0.0) (2.32.3)\n",
            "Requirement already satisfied: langchain>=0.2.10 in /usr/local/lib/python3.11/dist-packages (from trulens-apps-langchain<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (0.3.26)\n",
            "Requirement already satisfied: langchain-core>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from trulens-apps-langchain<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (0.3.68)\n",
            "Requirement already satisfied: alembic<2.0.0,>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (1.16.4)\n",
            "Requirement already satisfied: dill<0.4.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (0.3.9)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (6.5.2)\n",
            "Requirement already satisfied: munch<3.0.0,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (2.5.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0,>=1.5 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (2.0.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-proto>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (1.34.1)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (24.2)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (2.2.2)\n",
            "Requirement already satisfied: python-dotenv<2.0,>=0.21 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (1.1.1)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.6.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (13.9.4)\n",
            "Requirement already satisfied: sqlalchemy<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (2.0.41)\n",
            "Requirement already satisfied: trulens-otel-semconv<2.0.0,>=1.4.9 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (1.5.3)\n",
            "Requirement already satisfied: wrapt>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (1.17.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2.0.0,>=1.8.1->trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (1.1.3)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain>=0.2.10->trulens-apps-langchain<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain>=0.2.10->trulens-apps-langchain<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (0.4.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain>=0.2.10->trulens-apps-langchain<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.2.0->trulens-apps-langchain<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.2.0->trulens-apps-langchain<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (1.33)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (1.93.0)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (2.1.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (1.1.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (3.5)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (11.2.1)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (80.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (4.67.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.9.0)\n",
            "Requirement already satisfied: llama-cloud==0.1.32 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.1.32)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.32->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (2025.6.15)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (4.13.4)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.7.1)\n",
            "Requirement already satisfied: pypdf<6,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (5.7.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.6.43)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from munch<3.0.0,>=2.5.0->trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (1.5.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.23.0->trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (8.7.0)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto>=1.23.0->trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.23.0->trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (0.55b1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.3.3->trulens-apps-llamaindex>=1.0.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.3.3->trulens-apps-llamaindex>=1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.3.3->trulens-apps-llamaindex>=1.0.0) (2.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.6.0->trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.6.0->trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0,>=2.0->trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (3.2.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (4.3.8)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (2.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.23.0->trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.2.0->trulens-apps-langchain<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain>=0.2.10->trulens-apps-langchain<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain>=0.2.10->trulens-apps-langchain<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain>=0.2.10->trulens-apps-langchain<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (0.23.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.2.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.43 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.6.43)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->trulens-core<2.0.0,>=1.0.0->trulens-apps-llamaindex>=1.0.0) (0.1.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (1.3.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (3.26.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama-index>=0.11->trulens-apps-llamaindex>=1.0.0) (3.0.2)\n",
            "Downloading trulens_apps_llamaindex-1.5.3-py3-none-any.whl (10 kB)\n",
            "Downloading trulens_apps_langchain-1.5.3-py3-none-any.whl (9.1 kB)\n",
            "Installing collected packages: trulens-apps-langchain, trulens-apps-llamaindex\n",
            "Successfully installed trulens-apps-langchain-1.5.3 trulens-apps-llamaindex-1.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "trulens"
                ]
              },
              "id": "0f6e0698d57e480bb8535ac930a2439a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "# from llama_index.llms.langchain import LangChainLLM\n",
        "\n",
        "from google.colab import userdata\n",
        "hf_token = userdata.get(\"llama3\")  # Make sure it's stored correctly\n",
        "\n",
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    token=hf_token,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "llm_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=256,\n",
        "    temperature=0.1,\n",
        "    top_p=0.9,\n",
        "    return_full_text=False,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=llm_pipeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "3225be5b40da496eb3767405ede6bec3",
            "606088ed949043209545162672568f4e",
            "7e26852f8a2e4c4ea2256e84fa5c2f09",
            "05f46dec29b44438b657c68b7564291f",
            "86b6e8b7fcd647b4a4c3182d78a8cd61",
            "15e7091ba0ad4bdda900e0d1742ac3d8",
            "5fb3c8cbec964b81ad76868fc5a18c14",
            "03f3cc4840294c1480f64f767a9831ba",
            "dd6c453e1faf40d98be45e552e1ec198",
            "d61e2f3e74da47e4bee29eb65676612f",
            "a2996e26ee0144faaa2b6ff3206dd4a7"
          ]
        },
        "id": "sSMHnji6i65Z",
        "outputId": "003a2a0d-f5a7-45bb-ffe9-7ec817fbb3ea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3225be5b40da496eb3767405ede6bec3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/tmp/ipython-input-1-1345738778.py:30: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=llm_pipeline)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  # or any other HF-compatible model\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "qDfrPj6BkPdH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !curl https://www.ipcc.ch/report/ar6/wg2/downloads/report/IPCC_AR6_WGII_Chapter03.pdf --output IPCC_AR6_WGII_Chapter03.pdf\n",
        "\n",
        "\n",
        "from pypdf import PdfReader, PdfWriter\n",
        "import io\n",
        "\n",
        "def select_pdf_pages(file, pages):\n",
        "    pdf_reader = PdfReader(file)\n",
        "    pdf_writer = PdfWriter()\n",
        "    for page in pages:\n",
        "        pdf_writer.add_page(pdf_reader.pages[page])\n",
        "\n",
        "    buf = io.BytesIO()\n",
        "    pdf_writer.write(buf)\n",
        "    buf.seek(0)\n",
        "    return buf\n",
        "\n",
        "new_pdf = select_pdf_pages(\n",
        "    open(\"IPCC_AR6_WGII_Chapter03.pdf\", \"rb\"), list(range(0, 30))\n",
        ")\n",
        "with open(\"IPCC_AR6_WGII_Chapter03_subset.pdf\", \"wb\") as f:\n",
        "    f.write(new_pdf.getvalue())\n"
      ],
      "metadata": {
        "id": "KeZ5WBYJkdrM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
        "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
        "\n",
        "# Set global defaults for LLM and embedding model\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "# Load documents\n",
        "documents = SimpleDirectoryReader(input_files=[\"IPCC_AR6_WGII_Chapter03_subset.pdf\"]).load_data()\n",
        "\n",
        "# Build basic index using updated approach\n",
        "def build_basic_index(documents):\n",
        "    return VectorStoreIndex.from_documents(documents)\n",
        "\n",
        "\n",
        "def build_sentence_window_index(documents):\n",
        "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
        "        window_size=3,\n",
        "        window_metadata_key=\"window\",\n",
        "        original_text_metadata_key=\"original-text\"\n",
        "    )\n",
        "    # Use Settings instead of ServiceContext\n",
        "    Settings.node_parser = node_parser\n",
        "    return VectorStoreIndex.from_documents(documents=documents)"
      ],
      "metadata": {
        "id": "kCir1pusk0E1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval import TruLlama, Tru\n",
        "\n",
        "tru = Tru()\n",
        "\n",
        "def get_trulens_recorder(query_engine, app_id):\n",
        "    return TruLlama(query_engine, app_id=app_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U81M4Ce8lSNK",
        "outputId": "86d959bb-2443-45d0-f632-c38fc133d28c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-6-1457315951.py:1: DeprecationWarning: The `trulens_eval` module is deprecated. See https://www.trulens.org/component_guides/other/trulens_eval_migration/ for instructions on migrating to `trulens.*` modules.\n",
            "  from trulens_eval import TruLlama, Tru\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦑 Initialized with db url sqlite:///default.sqlite .\n",
            "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "qa_df = pd.read_csv(\"ipcc_test_questions.csv\")\n",
        "qa_set = [{\"query\": row[\"Question\"], \"response\": row[\"Answer\"]} for _, row in qa_df.iterrows()]\n",
        "\n",
        "len(qa_set)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hakzFya4lycD",
        "outputId": "c8092ad0-8e20-4169-f916-1d968de58f90"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basic_query_index = build_basic_index(documents)\n",
        "basic_query_engine = basic_query_index.as_query_engine()\n",
        "\n",
        "recorder = get_trulens_recorder(basic_query_engine, app_id=\"LLaMA3_Basic\")\n",
        "with recorder as recording:\n",
        "    for q in qa_set[:4]:\n",
        "        print(\"Query:\", q[\"query\"])\n",
        "        print(\"Answer:\", basic_query_engine.query(q[\"query\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TfR4GIho_iW",
        "outputId": "dfebef09-00e3-47e5-8ce6-244d7ee72158"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.embeddings.multi_modal_base.MultiModalEmbedding'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.base.embeddings.base.BaseEmbedding'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'llama_index.core.callbacks.base_handler.BaseCallbackHandler'>\n",
            "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.types.BasePydanticVectorStore'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.base.BaseIndex'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'typing.Generic'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'llama_index.core.graph_stores.types.GraphStore'>\n",
            "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Protocol'>\n",
            "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Generic'>\n",
            "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.MetadataAwareTextSplitter'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.TextSplitter'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.NodeParser'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.keyval_docstore.KVDocumentStore'>\n",
            "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.types.BaseDocumentStore'>\n",
            "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'llama_index.core.data_structs.data_structs.IndexStruct'>\n",
            "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
            "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.storage.storage_context.StorageContext'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'>\n",
            "\tinstrumenting retrieve\n",
            "\tinstrumenting _retrieve\n",
            "\tinstrumenting _aretrieve\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.base_retriever.BaseRetriever'>\n",
            "\tinstrumenting retrieve\n",
            "\tinstrumenting _retrieve\n",
            "\tinstrumenting _aretrieve\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'llama_index.llms.langchain.base.LangChainLLM'>\n",
            "\tinstrumenting chat\n",
            "\tinstrumenting complete\n",
            "\tinstrumenting stream_chat\n",
            "\tinstrumenting stream_complete\n",
            "\tinstrumenting achat\n",
            "\tinstrumenting acomplete\n",
            "\tinstrumenting astream_chat\n",
            "\tinstrumenting astream_complete\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'llama_index.core.llms.llm.LLM'>\n",
            "\tinstrumenting chat\n",
            "\tinstrumenting complete\n",
            "\tinstrumenting stream_chat\n",
            "\tinstrumenting stream_complete\n",
            "\tinstrumenting achat\n",
            "\tinstrumenting acomplete\n",
            "\tinstrumenting astream_chat\n",
            "\tinstrumenting astream_complete\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'llama_index.core.base.llms.base.BaseLLM'>\n",
            "\tinstrumenting chat\n",
            "\tinstrumenting complete\n",
            "\tinstrumenting stream_chat\n",
            "\tinstrumenting stream_complete\n",
            "\tinstrumenting achat\n",
            "\tinstrumenting acomplete\n",
            "\tinstrumenting astream_chat\n",
            "\tinstrumenting astream_complete\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'object'>\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_core.language_models.llms.BaseLLM'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_core.language_models.base.BaseLanguageModel[str]'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_core.language_models.base.BaseLanguageModel'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_core.runnables.base.RunnableSerializable[Union[PromptValue, str, Sequence[Union[BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]], ~LanguageModelOutputVar]'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_core.runnables.base.RunnableSerializable'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_core.load.serializable.Serializable'>\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_core.runnables.base.Runnable'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'typing.Generic'>\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'llama_index.core.base.llms.types.LLMMetadata'>\n",
            "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.indices.prompt_helper.PromptHelper'>\n",
            "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
            "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'>\n",
            "\tinstrumenting get_response\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.refine.Refine'>\n",
            "\tinstrumenting get_response\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.base.BaseSynthesizer'>\n",
            "\tinstrumenting get_response\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'>\n",
            "\tinstrumenting query\n",
            "\tinstrumenting aquery\n",
            "\tinstrumenting synthesize\n",
            "\tinstrumenting asynthesize\n",
            "\tinstrumenting retrieve\n",
            "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.base_query_engine.BaseQueryEngine'>\n",
            "\tinstrumenting query\n",
            "\tinstrumenting aquery\n",
            "\tinstrumenting synthesize\n",
            "\tinstrumenting asynthesize\n",
            "\tinstrumenting retrieve\n",
            "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
            "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
            "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
            "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'object'>\n",
            "Query: What are the primary impacts of climate change on ocean and coastal ecosystems?\n",
            "Answer:  According to the IPCC AR6 WGII Chapter 3, the primary impacts of climate change on ocean and coastal ecosystems include:\n",
            "1. Changes in the physical and chemical characteristics of the ocean, such as warming, acidification, and deoxygenation.\n",
            "2. Shifts in the distribution, abundance, and timing of seasonal activities of oceanic and coastal organisms, from microbes to mammals.\n",
            "3. Geographic range shifts of marine species, with a mean rate of 59.2 ± 15.5 km per decade, and substantial variation in responses among taxa and regions.\n",
            "4. Seasonal events occurring earlier, with planktonic organisms experiencing a shift of 4.3 ± 1.8 d to 7.5 ± 1.5 d per decade, and fish experiencing a shift of 3 ± 2.1 d per decade.\n",
            "5. Alterations to ecological communities, including increased spread of physiologically suboptimal conditions for many marine fish and invertebrates.\n",
            "6. Habitat loss, population declines, increased risks of species extirpations and extinctions, and rearrangement of marine food webs.\n",
            "\n",
            "These impacts are attributed to human-induced climate change, and are supported by multiple lines of evidence, including paleorecords, contemporary observations, manipulation experiments, and models. The evidence is based on observations over recent decades, laboratory studies, and process studies, as well as Indigenous knowledge and local knowledge. The impacts are expected to continue and worsen unless mitigative actions are taken to reduce greenhouse gas emissions and adapt to the changing climate.\n",
            "Query: How do marine heatwaves affect ocean ecosystems?\n",
            "Answer:  The text does not explicitly discuss marine heatwaves and their effects on ocean ecosystems. However, it does mention that ocean warming, acidification, and deoxygenation are altering ecological communities by increasing the spread of physiologically suboptimal conditions for many marine fish and invertebrates. It also mentions that warming, acidification, and deoxygenation are altering ecological communities by increasing the spread of physiologically suboptimal conditions for many marine fish and invertebrates. This suggests that changes in ocean temperature and chemistry can have negative impacts on marine ecosystems. However, the text does not specifically discuss marine heatwaves, which are a type of extreme weather event characterized by prolonged periods of abnormally high sea surface temperatures. To answer this question, additional information would be needed. \n",
            "\n",
            "page_label: 9\n",
            "file_path: IPCC_AR6_WGII_Chapter03_subset.pdf\n",
            "\n",
            "3\n",
            "387\n",
            "Oceans and Coastal Ecosystems and Their Services  Chapter 3\n",
            "Frequently Asked Questions\n",
            "FAQ 3.1 | How do we know which changes to marine ecosystems are specifically caused by climate change?\n",
            "To attribute changes in marine ecosystems to human-induced climate change, scientists use paleorecords (reconstructing the links between \n",
            "climate, evolutionary and ecological changes in the geological past), contemporary observations (assessing current climate and ecological \n",
            "responses in the field and through experiments) and models. We refer to these as multiple lines of evidence, meaning that the evidence comes \n",
            "from diverse approaches, as described below.\n",
            "Emissions of greenhouse gases like carbon dioxide from human activity cause ocean warming, acidification, oxygen \n",
            "loss, and other physical and chemical changes that are affecting marine ecosystems around the world. At the same \n",
            "time, natural climate variability and direct human impacts, such as overfishing and pollution, also affect marine \n",
            "ecosystems locally, regionally and globally. These climate and non-climate impact drivers counteract each other, add \n",
            "up or multiply to produce smaller or larger changes than expected from individual drivers. Attribution of changes in \n",
            "marine ecosystems requires evaluating the often-interacting roles of natural climate variability, non-climate drivers, \n",
            "and human-induced climate change. To do this work, scientists use\n",
            "• paleorecords: reconstructing the links between climate and evolutionary and ecological changes of the past;\n",
            "• contemporary observations: assessing current climate and ecological responses;\n",
            "• manipulation experiments: measuring responses of organisms and ecosystems to different climate conditions; and\n",
            "• models: testing whether we understand how organisms and ecosystems are impacted by different stressors, and \n",
            "quantifying the relative importance of different stressors.\n",
            "Paleorecords can be used to trace the correlation between past changes in climate and marine life. Paleoclimate is \n",
            "reconstructed from the chemical composition of shells and teeth or from sediments and ice cores. Changes to sea \n",
            "life signalled by changing biodiversity, extinction or distributional shifts are reconstructed from fossils. Using large \n",
            "datasets, we can infer the effects of climate change on sea life over relatively long time scales⎯usually hundreds to \n",
            "millions of years. The advantage of paleorecords is that they provide insights into how climate change affects life \n",
            "from organisms to ecosystems, without the complicating influence of direct human impacts. A key drawback is that \n",
            "the paleo and modern worlds do not have fully comparable paleoclimate regimes, dominant marine species and \n",
            "rates of climate change. Nevertheless, the paleorecord can be used to derive fundamental rules by which organisms, \n",
            "ecosystems, environments and regions are typically most affected by climate change. For example, the paleorecord \n",
            "shows that coral reefs repeatedly underwent declines during past warming events, supporting the inference that \n",
            "corals may not be able to adapt to current climate warming.\n",
            "Contemporary observations over recent decades allow scientists to relate the status of marine species and \n",
            "ecosystems to changes in climate or other factors. For example, scientists compile large datasets to determine \n",
            "whether species usually associated with warm water are appearing in traditionally cool-water areas that are rapidly \n",
            "warming. A similar pattern observed in multiple regions and over several decades (i.e., longer than time scales \n",
            "of natural variability) provides confidence that climate change is altering community structure. This evidence is \n",
            "weighed against findings from other approaches, such as manipulation experiments, to provide a robust picture of \n",
            "climate-change impacts in the modern ocean.\n",
            "In manipulation experiments, scientists expose organisms or communities of organisms to multiple stressors, for \n",
            "example, elevated CO 2, high temperature, or both, based on values drawn from future climate projections. Such \n",
            "experiments will involve multiple treatments (e.g., in different aquarium tanks) in which organisms are exposed \n",
            "to different combinations of the stressors. This approach enables scientists to understand the effects of individual \n",
            "stressors as well as their interactions to explore physiological thresholds of marine organisms and communities. \n",
            "The scale of manipulation experiments can range from small tabletop tanks to large installations or natural ocean \n",
            "experiments involving tens of thousands of litres of water.\n",
            "Ecological effects of climate change are also explored within models developed from fundamental scientific principles \n",
            "and observations. Using these numerical representations of marine ecosystems, scientists can explore how different \n",
            "levels of climate change and non-climate stressors influence species and ecosystems at scales not possible with \n",
            "experiments. Models are commonly used to simulate the ecological response to climate change over recent decades \n",
            "and centuries. Convergence between the model results and the observations suggests that our understanding of the \n",
            "key processes is sufficient to attribute the observed ecological changes to climate change, and to use the models to \n",
            "project future ecological changes. Differences between model results and observations indicate gaps in knowledge \n",
            "to be filled in order to better detect and attribute the impacts of climate change on marine life.\n",
            "---------------------\n",
            "Given the context information and not prior knowledge, answer the query.\n",
            "Query: How do marine heatwaves affect ocean ecosystems?\n",
            "Answer:  The text does not explicitly discuss marine heatwaves and their effects on ocean ecosystems. However, it does mention that ocean warming, acidification, and deoxygenation are altering ecological communities by increasing the spread of physiologically suboptimal conditions for many marine fish and invertebrates. It also mentions that warming, acidification, and deoxygenation are altering ecological communities by increasing the spread of physiologically suboptimal conditions for many marine fish and invertebrates. This suggests that changes in ocean temperature and chemistry can have negative impacts on marine ecosystems. However, the text does not specifically discuss marine heatwaves, which are a type of extreme weather event characterized by prolonged periods of abnormally high sea surface temperatures. To answer this question, additional information would be needed. \n",
            "\n",
            "page_label: 9\n",
            "file_path: IPCC_AR6_WGII_Chapter03_subset.pdf\n",
            "\n",
            "3\n",
            "387\n",
            "Oceans and Coastal Ecosystems and Their Services  Chapter 3\n",
            "Frequently Asked Questions\n",
            "FAQ 3.1 | How do we know which changes to marine ecosystems are specifically caused by climate change?\n",
            "To attribute changes in marine ecosystems to human-induced climate change, scientists use paleorecords (reconstructing the links between \n",
            "climate, evolutionary and ecological changes in the geological past), contemporary observations (assessing current climate and ecological \n",
            "responses in the field and through experiments) and models. We refer to these as multiple lines of evidence, meaning that the evidence comes \n",
            "from diverse approaches, as described below.\n",
            "Emissions of greenhouse gases like carbon dioxide from human activity cause ocean warming, acidification, oxygen \n",
            "loss, and other physical and chemical changes that are affecting marine ecosystems around the world. At the same \n",
            "time, natural climate variability and direct human impacts, such as overfishing and pollution, also affect marine \n",
            "ecosystems locally, regionally and globally. These climate and non-climate impact drivers counteract each other, add \n",
            "up or multiply to produce smaller or larger changes than expected from individual drivers. Attribution of changes in \n",
            "marine ecosystems requires evaluating the often-interacting roles of natural climate variability, non-climate drivers, \n",
            "and human-induced climate change. To do this work, scientists use\n",
            "• paleorecords: reconstructing the links between climate and evolutionary and ecological changes of the past;\n",
            "• contemporary observations: assessing current climate and ecological responses;\n",
            "• manipulation experiments: measuring responses of organisms and ecosystems to different climate conditions; and\n",
            "• models: testing whether we understand how organisms and ecosystems are impacted by different stressors, and \n",
            "quantifying the relative importance of different stressors.\n",
            "Paleorecords can be used to trace the correlation between past changes in climate and marine life. Paleoclimate is \n",
            "reconstructed from the chemical composition of shells and teeth or from sediments and ice cores. Changes to sea \n",
            "life signalled by changing biodiversity, extinction or distributional shifts are reconstructed from fossils. Using large \n",
            "datasets, we can infer the effects of climate change on sea life over relatively long time scales⎯usually hundreds to \n",
            "millions of years. The advantage of paleorecords is that they provide insights into how climate change affects life \n",
            "from organisms to ecosystems, without the complicating influence of direct human impacts. A key drawback is that \n",
            "the paleo and modern worlds do not have fully comparable paleoclimate regimes, dominant marine species and \n",
            "rates of climate change. Nevertheless, the paleorecord can be used to derive fundamental rules by which organisms, \n",
            "ecosystems, environments and regions are typically most affected by climate change. For example, the paleorecord \n",
            "shows that coral reefs repeatedly underwent declines during past warming events, supporting the inference that \n",
            "corals may not be able to adapt to current climate warming.\n",
            "Contemporary observations over recent decades allow scientists to relate the status of marine species and \n",
            "ecosystems to changes in climate or other factors. For example, scientists compile large datasets to determine \n",
            "whether species usually associated with warm water are appearing in traditionally cool-water areas that are rapidly \n",
            "warming. A similar pattern observed in multiple regions and over several decades (i.e., longer than time scales \n",
            "of natural variability) provides confidence that climate change is altering community structure. This evidence is \n",
            "weighed against findings from other approaches, such as manipulation experiments, to\n",
            "Query: What role does the ocean play in global climate regulation?\n",
            "Answer:  According to the text, the ocean plays a crucial role in global climate regulation by \"modulating the global climate system by regulating cycles of heat, water and elements, including carbon.\" This suggests that the ocean helps to regulate the Earth's climate by controlling the flow of heat, water, and other elements that are important for maintaining a stable global climate.\n",
            "Query: How is climate change impacting marine biodiversity?\n",
            "Answer:  Climate change is impacting marine biodiversity in various ways. It is causing ocean warming, acidification, oxygen loss, and other physical and chemical changes that are affecting marine ecosystems around the world. At the same time, natural climate variability and direct human impacts, such as overfishing and pollution, also affect marine ecosystems locally, regionally, and globally. These climate and non-climate impact drivers counteract each other, add up or multiply to produce smaller or larger changes than expected from individual drivers. Attribution of changes in marine ecosystems requires evaluating the often-interacting roles of natural climate variability, non-climate drivers, and human-induced climate change. Scientists use paleorecords, contemporary observations, manipulation experiments, and models to understand the impacts of climate change on marine biodiversity. The paleorecord shows that coral reefs repeatedly underwent declines during past warming events, supporting the inference that corals may not be able to adapt to current climate warming. Contemporary observations over recent decades allow scientists to relate the status of marine species and ecosystems to changes in climate or other factors. Manipulation experiments enable scientists to understand the effects of individual stressors as well as their interactions to explore physiological thresholds of marine organisms and communities. Models are used to simulate the ecological response to climate change over recent decades and centuries. Convergence between the model results and the observations suggests that our understanding of the key processes is sufficient to attribute the observed ecological changes to climate change, and to use the models to project future ecological changes. Differences between model results and observations indicate gaps in knowledge to be filled in order to better detect and attribute the impacts of climate change on marine life. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.indices.postprocessor import MetadataReplacementPostProcessor\n",
        "sentence_window_index = build_sentence_window_index(documents=documents)\n",
        "\n",
        "postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
        "\n",
        "sentence_query_engine = sentence_window_index.as_query_engine(\n",
        "    node_postprocessors=[postproc]\n",
        ")\n",
        "\n",
        "sentence_recorder = get_trulens_recorder(\n",
        "    sentence_query_engine, app_id=\"Sentence Window Query Engine\"\n",
        ")\n",
        "with sentence_recorder as recording:\n",
        "    for q in qa_set[:4]:\n",
        "        sentence_query_engine.query(q['query'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgYZH2wBpMQj",
        "outputId": "55d89fac-8afb-4904-e43d-a9ea9bfe6fb1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.embeddings.multi_modal_base.MultiModalEmbedding'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.base.embeddings.base.BaseEmbedding'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'llama_index.core.callbacks.base_handler.BaseCallbackHandler'>\n",
            "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.types.BasePydanticVectorStore'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.base.BaseIndex'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'typing.Generic'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'llama_index.core.graph_stores.types.GraphStore'>\n",
            "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Protocol'>\n",
            "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Generic'>\n",
            "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.MetadataAwareTextSplitter'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.TextSplitter'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.NodeParser'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.keyval_docstore.KVDocumentStore'>\n",
            "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.types.BaseDocumentStore'>\n",
            "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'llama_index.core.data_structs.data_structs.IndexStruct'>\n",
            "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
            "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.storage.storage_context.StorageContext'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'>\n",
            "\tinstrumenting retrieve\n",
            "\tinstrumenting _retrieve\n",
            "\tinstrumenting _aretrieve\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.base_retriever.BaseRetriever'>\n",
            "\tinstrumenting retrieve\n",
            "\tinstrumenting _retrieve\n",
            "\tinstrumenting _aretrieve\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'llama_index.llms.langchain.base.LangChainLLM'>\n",
            "\tinstrumenting chat\n",
            "\tinstrumenting complete\n",
            "\tinstrumenting stream_chat\n",
            "\tinstrumenting stream_complete\n",
            "\tinstrumenting achat\n",
            "\tinstrumenting acomplete\n",
            "\tinstrumenting astream_chat\n",
            "\tinstrumenting astream_complete\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'llama_index.core.llms.llm.LLM'>\n",
            "\tinstrumenting chat\n",
            "\tinstrumenting complete\n",
            "\tinstrumenting stream_chat\n",
            "\tinstrumenting stream_complete\n",
            "\tinstrumenting achat\n",
            "\tinstrumenting acomplete\n",
            "\tinstrumenting astream_chat\n",
            "\tinstrumenting astream_complete\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'llama_index.core.base.llms.base.BaseLLM'>\n",
            "\tinstrumenting chat\n",
            "\tinstrumenting complete\n",
            "\tinstrumenting stream_chat\n",
            "\tinstrumenting stream_complete\n",
            "\tinstrumenting achat\n",
            "\tinstrumenting acomplete\n",
            "\tinstrumenting astream_chat\n",
            "\tinstrumenting astream_complete\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.llms.langchain.base.LangChainLLM'> for base <class 'object'>\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_core.language_models.llms.BaseLLM'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_core.language_models.base.BaseLanguageModel[str]'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_core.language_models.base.BaseLanguageModel'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_core.runnables.base.RunnableSerializable[Union[PromptValue, str, Sequence[Union[BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]], ~LanguageModelOutputVar]'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_core.runnables.base.RunnableSerializable'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_core.load.serializable.Serializable'>\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'langchain_core.runnables.base.Runnable'>\n",
            "\tinstrumenting invoke\n",
            "\tinstrumenting ainvoke\n",
            "\tinstrumenting stream\n",
            "\tinstrumenting astream\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'typing.Generic'>\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'langchain_community.llms.huggingface_pipeline.HuggingFacePipeline'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'llama_index.core.base.llms.types.LLMMetadata'>\n",
            "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.indices.prompt_helper.PromptHelper'>\n",
            "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
            "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'>\n",
            "\tinstrumenting get_response\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.refine.Refine'>\n",
            "\tinstrumenting get_response\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.base.BaseSynthesizer'>\n",
            "\tinstrumenting get_response\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'>\n",
            "\tinstrumenting query\n",
            "\tinstrumenting aquery\n",
            "\tinstrumenting synthesize\n",
            "\tinstrumenting asynthesize\n",
            "\tinstrumenting retrieve\n",
            "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.base_query_engine.BaseQueryEngine'>\n",
            "\tinstrumenting query\n",
            "\tinstrumenting aquery\n",
            "\tinstrumenting synthesize\n",
            "\tinstrumenting asynthesize\n",
            "\tinstrumenting retrieve\n",
            "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
            "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
            "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
            "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'object'>\n",
            "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'>\n",
            "\tinstrumenting _postprocess_nodes\n",
            "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.postprocessor.types.BaseNodePostprocessor'>\n",
            "\tinstrumenting _postprocess_nodes\n",
            "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
            "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
            "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'pydantic.main.BaseModel'>\n",
            "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
            "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'abc.ABC'>\n",
            "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'object'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y trulens_eval\n",
        "# !pip install -qU trulens_eval\n",
        "!pip install trulens-providers-huggingface\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JtP4tRKMujUQ",
        "outputId": "9c65e022-3368-4925-a4e8-9b0ef3b7216a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trulens-providers-huggingface\n",
            "  Downloading trulens_providers_huggingface-1.5.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from trulens-providers-huggingface) (3.9.1)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from trulens-providers-huggingface) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.31 in /usr/local/lib/python3.11/dist-packages (from trulens-providers-huggingface) (2.32.3)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from trulens-providers-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.1 in /usr/local/lib/python3.11/dist-packages (from trulens-providers-huggingface) (4.53.1)\n",
            "Requirement already satisfied: trulens-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from trulens-providers-huggingface) (1.5.3)\n",
            "Requirement already satisfied: trulens-feedback<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from trulens-providers-huggingface) (1.5.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.9.1->trulens-providers-huggingface) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.9.1->trulens-providers-huggingface) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.9.1->trulens-providers-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.9.1->trulens-providers-huggingface) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->trulens-providers-huggingface) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->trulens-providers-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->trulens-providers-huggingface) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->trulens-providers-huggingface) (2025.6.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.38.1->trulens-providers-huggingface) (0.33.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.38.1->trulens-providers-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.38.1->trulens-providers-huggingface) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.38.1->trulens-providers-huggingface) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.38.1->trulens-providers-huggingface) (0.5.3)\n",
            "Requirement already satisfied: alembic<2.0.0,>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (1.16.4)\n",
            "Requirement already satisfied: dill<0.4.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (0.3.9)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (6.5.2)\n",
            "Requirement already satisfied: munch<3.0.0,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (2.5.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0,>=1.5 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (1.6.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-proto>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (1.34.1)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (2.2.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (2.11.7)\n",
            "Requirement already satisfied: python-dotenv<2.0,>=0.21 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (1.1.1)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.6.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (13.9.4)\n",
            "Requirement already satisfied: sqlalchemy<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (2.0.41)\n",
            "Requirement already satisfied: trulens-otel-semconv<2.0.0,>=1.4.9 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (1.5.3)\n",
            "Requirement already satisfied: wrapt>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (1.17.2)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trulens-feedback<2.0.0,>=1.0.0->trulens-providers-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from trulens-feedback<2.0.0,>=1.0.0->trulens-providers-huggingface) (1.15.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2.0.0,>=1.8.1->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (1.1.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers<5.0.0,>=4.38.1->trulens-providers-huggingface) (1.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from munch<3.0.0,>=2.5.0->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (1.17.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.23.0->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (8.7.0)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto>=1.23.0->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.23.0->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (0.55b1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.6.0->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.6.0->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (2.19.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.3.0->trulens-feedback<2.0.0,>=1.0.0->trulens-providers-huggingface) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0,>=2.0->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (3.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->trulens-providers-huggingface) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.23.0->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->trulens-core<2.0.0,>=1.0.0->trulens-providers-huggingface) (0.1.2)\n",
            "Downloading trulens_providers_huggingface-1.5.3-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: trulens-providers-huggingface\n",
            "Successfully installed trulens-providers-huggingface-1.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "trulens"
                ]
              },
              "id": "fe148cec1ab6416e94626e7f82f07c57"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -qU trulens_eval sentence-transformers\n",
        "# !pip install --quiet \"trulens_eval>=0.24.0\"\n",
        "\n",
        "\n",
        "from trulens_eval import Tru, Feedback, TruLlama\n",
        "from trulens.providers.huggingface import Huggingface\n",
        "import numpy as np\n",
        "\n",
        "# Initialize TruLens\n",
        "tru = Tru()\n",
        "\n",
        "# Initialize HuggingFace provider\n",
        "huggingface_provider = Huggingface(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Define feedback function\n",
        "f_qa_relevance = Feedback(\n",
        "    huggingface_provider.relevance_with_cot_reasons,\n",
        "    name=\"Answer Relevance\"\n",
        ").on_input_output()\n",
        "\n",
        "\n",
        "# Context relevance (source-grounding)\n",
        "f_qs_relevance = Feedback(\n",
        "    huggingface_provider.relevance_with_cot_reasons, name=\"Context Relevance\"\n",
        ").on_input().on(TruLlama.select_source_nodes().node.text).aggregate(np.mean)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "Wvz5j-sosr1Y",
        "outputId": "10a47a85-1885-4a96-938f-e0904a821fd3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Huggingface' object has no attribute 'relevance_with_cot_reasons'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-15-1351429402.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Define feedback function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m f_qa_relevance = Feedback(\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mhuggingface_provider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelevance_with_cot_reasons\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Answer Relevance\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m ).on_input_output()\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    989\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m                         \u001b[0;31m# this is the current error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{type(self).__name__!r} object has no attribute {item!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Huggingface' object has no attribute 'relevance_with_cot_reasons'"
          ]
        }
      ]
    }
  ]
}